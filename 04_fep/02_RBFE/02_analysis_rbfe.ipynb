{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Binding Free Energy (RBFE) Network Tutorial - Analysis\n",
    "\n",
    "This Jupyter notebook is a tutorial on an analysis workflow for RBFE calculations using a Free Energy Perturbation (FEP) network with BioSimSpace.    \n",
    "\n",
    "This notebook includes core as well as <span style=\"color:teal\">extra</span> options. These extra sections are there to include some more functionality for when the concepts of these tutorials are applied to your own work.  \n",
    "**<span style=\"color:teal\">Reading Time:</span>**\n",
    "~ 30 mins\n",
    "\n",
    "### Maintainers\n",
    "- [Anna Herz -- @annamherz](https://github.com/annamherz)\n",
    "\n",
    "See [README.md](https://github.com/michellab/BioSimSpaceTutorials/blob/main/04_fep/README.md) for complete list of authors.\n",
    "\n",
    "### Prerequisites\n",
    " - Basic Python\n",
    " - Part 1 of this workshop (An Introduction to setting up alchemical free energy calculations)\n",
    "    - this should include basic knowledge of the principles behind RBFE\n",
    " - The 01_setup_rbfe notebook\n",
    "\n",
    "### Learning Objectives\n",
    " - Analyse and plot the results of an FEP pipeline setup using BSS.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Analysing the edges of the Network](#intro)    \n",
    "    1.1 [Analysing repeats](#reps)     \n",
    "    1.2 [Experimental binding affinities](#exp)      \n",
    "    1.3 [Plotting](#plot)      \n",
    "2. [Analysing per Ligand](#lig)   \n",
    "    2.1 [Freenrgworkflows](#fwf)     \n",
    "    2.2 [Plotting](#plot2)    \n",
    "    2.3 [Statistical analysis](#stats)     \n",
    "    2.4 [Outliers](#outliers)  \n",
    "\n",
    "### Further reading for this topic\n",
    "- [LiveComs Best Practices for Alchemical Free Energy Calculations](https://livecomsjournal.org/index.php/livecoms/article/view/v2i1e18378).\n",
    "\n",
    "**<span style=\"color:black\">Jupyter Cheat Sheet</span>**\n",
    "- To run the currently highlighted cell and move focus to the next cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "- To run the currently highlighted cell and keep focus in the same cell, hold <kbd>&#x21E7; ctrl</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "- To get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;\n",
    "- You can find the full documentation at [biosimspace.org](https://biosimspace.org).\n",
    "\n",
    "You can use `!` to access terminal commands: e.g. `! head -n 20 myfilename.dat` will display the first 20 lines of a file. \n",
    "\n",
    "\n",
    "### Exercises\n",
    "Exercises are announced using an alert alert-success box in this way:\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Exercise 1.1: Write a function that computes bond lengths:</b>\n",
    "</div>\n",
    "and followed by an incomplete cell. All exercises should be numbered. \n",
    "Missing parts are indicated by:\n",
    "\n",
    "```python\n",
    "#FIXME\n",
    "```\n",
    "These are included whilst running through the workshops and also in dedicated sections.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import BioSimSpace as BSS\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.stats import sem as sem\n",
    "\n",
    "# import from path for freenrgworkflows.\n",
    "import sys\n",
    "sys.path.insert(1, '../freenrgworkflows/networkanalysis/')\n",
    "import networkanalysis\n",
    "import experiments\n",
    "import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "# define all the folder locations\n",
    "main_folder =  os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analysing the edges of the Network\n",
    "<a id=\"intro\"></a>\n",
    "\n",
    "Once we have obtained our results, we want to analyse them. The basics of this analysis using `BSS.FreeEnergy.Relative.analyse()` for both MBAR and TI, as well as plotting overlap matrices, have already been covered in the introduction to alchemistry part of this workshop.\n",
    "\n",
    "In this part, we will look at how to carry out a large scale network analysis. As it would take some time to run the analysis for each perturbation, the [runs from this paper](https://chemrxiv.org/engage/chemrxiv/article-details/62ec4b0eadfd35eddd272954) have already been analysed using BSS to give the MBAR RBFE result and error in a csv file format. It is best practice to run repeats of the simulations, which is why there are multiple results files, one for each repeat. The files 'analysis/repeat_{r}_tyk2.csv' contain the results for this 'analysis/network_full.dat'. These runs are from a very large network, with some different ligands than we used for the first part of this RBFE tutorial. This is included incase you want to create a different network and analyse how the output changes based on the edges chosen. However, in this tutorial we will not be analysing this whole large network and we have a different network file to describe the inital network we want to consider, generated using LOMAP, in 'analysis/network.dat', with the ligands from 'inputs/ligands/analysis_ligands'.\n",
    "\n",
    "There is also a csv file with the experimental results for these ligands. In cases where experimental data is available, for instance when benchmarking a new protein-ligand set, we would like to compare how well FEP is predicting with respect to these data.    \n",
    "\n",
    "First, we want to set the file paths to our results and experimental data. We also want to create a list of the perturbations and of ligands so we can use/edit these throughout the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected network\n",
    "# we will define the engine here for ease\n",
    "engine = \"SOMD\"\n",
    "\n",
    "# experimental values (e.g. ic50/ki) for all ligands in our set.\n",
    "exp_filepath = 'analysis/exp_data_tyk2.dat'\n",
    "\n",
    "# We also want to create a list of the perturbations in our network.\n",
    "# create a list of the perturbations\n",
    "perturbations = []\n",
    "\n",
    "# create a list of ligands\n",
    "ligands = []\n",
    "\n",
    "# use the network file to find the ligands and perturbations\n",
    "for line in open(\"analysis/network.dat\", \"r\"):\n",
    "    lig_0 = line.split()[0]\n",
    "    lig_1 = line.split()[1]\n",
    "    pert = f\"{lig_0}~{lig_1}\"\n",
    "    perturbations.append(pert)\n",
    "    if lig_0 not in ligands:\n",
    "        ligands.append(lig_0)\n",
    "    elif lig_1 not in ligands:\n",
    "        ligands.append(lig_1)\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to how we used NetworkX in the setup to visualise our adjusted network, we can also use it here to view the network we are analysing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the graph.\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Loop over the nligands and add as nodes to the graph.\n",
    "for lig in ligands:\n",
    "    graph.add_node(lig, label=lig, labelloc=\"t\")\n",
    "\n",
    "# Loop over the edges in the dictionary and add to the graph.\n",
    "for edge in perturbations:\n",
    "    lig_0 = edge.split(\"~\")[0]\n",
    "    lig_1 = edge.split(\"~\")[1]\n",
    "    graph.add_edge(lig_0, lig_1)\n",
    "\n",
    "# Plot the networkX graph.\n",
    "pos = nx.kamada_kawai_layout(graph)\n",
    "plt.figure(figsize=(8,8), dpi=150)\n",
    "nx.draw(\n",
    "    graph, pos, edge_color='black', width=1, linewidths=1,\n",
    "    node_size=1800, node_color='skyblue', font_size = 12,\n",
    "    labels={node: node for node in graph.nodes()})\n",
    "\n",
    "plt.savefig(\"analysis_network.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the network that we are considering, we want to get results files with these perturbations from the overall file that contains the large network results. We do not usually have to do this, but in this case it is neccessary to get the files that we need for analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_files = []\n",
    "no_repeats=6\n",
    "# create a list of the results files\n",
    "for r in list(range(1, no_repeats+1)):\n",
    "    file_name = f\"analysis/repeat_{r}_tyk2.csv\"\n",
    "    results_all_files.append(file_name)\n",
    "\n",
    "results_files = []\n",
    "\n",
    "for file in results_all_files:\n",
    "    new_file_name = f\"analysis/results_{results_all_files.index(file)}.csv\"\n",
    "    with open(new_file_name, \"w\") as result_file:\n",
    "\n",
    "        writer = csv.writer(result_file, delimiter=\",\")\n",
    "        writer.writerow([\"lig_1\",\"lig_2\",\"freenrg\",\"error\",\"engine\"])\n",
    "\n",
    "        for row, index in pd.read_csv(file).iterrows():\n",
    "            pert = f\"{index['lig_1']}~{index['lig_2']}\"\n",
    "            if pert in perturbations:\n",
    "                writer.writerow([index['lig_1'], index['lig_2'], index['freenrg'], index['error'], index['engine']])    \n",
    "\n",
    "        results_files.append(new_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Analysing repeats\n",
    "<a id=\"reps\"></a>  \n",
    "\n",
    "For the first analysis, we will look at the reproducibility between different repeats. We will calculate the average and SEM for the computed runs, based on their repeats. Here, we have six repeats for each. The SEM can be useful to see how reproducible the different runs are, and a larger SEM would indicate a perturbation that has poorer convergence between repeats.   \n",
    "\n",
    "In general, for our analyses, we will create a dictionary of the values. These can then be easily converted into a pandas dataframe for plotting. It is also a good idea to save output csv files, so that these are easily accessible in the future and can be loaded into python/excel again for any other plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary with the results of the files\n",
    "comp_dict_list = {}\n",
    "\n",
    "# append for results file\n",
    "for res_file in results_files:\n",
    "    res_df = pd.read_csv(res_file)\n",
    "    for index,row in res_df.iterrows():\n",
    "        lig_0 = row[0]\n",
    "        lig_1 = row[1]\n",
    "        pert = f\"{lig_0}~{lig_1}\"\n",
    "        # if not comp_dict_list[pert]:\n",
    "        #     print(\"oop\")\n",
    "        ddG = row[2]\n",
    "\n",
    "        if pert in comp_dict_list:\n",
    "            # Key exist in dict, check if is a list\n",
    "            if not isinstance(comp_dict_list[pert], list):\n",
    "                # If type is not list then make it list\n",
    "                comp_dict_list[pert] = [comp_dict_list[pert]]\n",
    "            # Append the value in list\n",
    "            comp_dict_list[pert].append(ddG)\n",
    "        else:\n",
    "            # As key is not in dict,\n",
    "            # so, add key-value pair\n",
    "            comp_dict_list[pert] = ddG\n",
    "\n",
    "# now calculate all the avg and SEM for the network perturbations\n",
    "# put these into a dictionary\n",
    "comp_diff_dict = {}\n",
    "\n",
    "# write these to a csv file\n",
    "with open(\"analysis/computed_perturbations_average.csv\", \"w\") as comp_pert_file:\n",
    "    writer = csv.writer(comp_pert_file, delimiter=\",\")\n",
    "    writer.writerow([\"lig_1\",\"lig_2\",\"freenrg\",\"error\",\"engine\"])\n",
    "    for pert in perturbations:\n",
    "        ddGs = comp_dict_list[pert]\n",
    "        lig_0 = pert.split(\"~\")[0]\n",
    "        lig_1 = pert.split(\"~\")[1]\n",
    "        comp_ddG = np.average(ddGs)\n",
    "        comp_err = sem(ddGs)\n",
    "\n",
    "        #update the dictionary for plotting later\n",
    "        comp_diff_dict.update({pert:(comp_ddG, comp_err)})\n",
    "\n",
    "        writer.writerow([lig_0, lig_1, comp_ddG, comp_err, engine])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Experimental binding affinities\n",
    "<a id=\"exp\"></a>\n",
    "\n",
    "Next, we want to visualise our results whilst comparing them to experimental values.\n",
    "In this example here, TYK2 has binding affinities in Ki, and can be converted using ΔG = RTlnK . It is important at this stage to make sure that the units match, so they are consequently converted into kcal/mol. We can carry out this conversion using the Freenrgworkflows library, and then use the results from that to calculate the experimental RBFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.ExperimentalData()\n",
    "experiments.compute_affinities(exp_filepath, data_type=\"IC50\", comments=\"#\", delimiter=\",\")\n",
    "experimental_DDGs = experiments.freeEnergiesInKcal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to turn the `experimental_DDGs`, which is a list of dictionaries, into a dictionary where we have the ligand as the key and a tuple of the binding affinity and assosciated error as the value. We can then use this to calculate what the experimental ΔΔG would be for each perturbation in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for the experimental values\n",
    "exper_val_dict = {}\n",
    "\n",
    "# convert the list of dicitonaries from freenrgworkflows into a single dictionary\n",
    "for lig_dict in experimental_DDGs:\n",
    "    lig_name = list(lig_dict.keys())[0]\n",
    "    exper = lig_dict[lig_name]\n",
    "    exper_err = lig_dict[\"error\"]\n",
    "    exper_val_dict.update({lig_name:(exper, exper_err)})\n",
    "\n",
    "# now that we have our dictionary, \n",
    "# we can also create a dictionary with all the experimental values for the perturbations\n",
    "exper_diff_dict = {}\n",
    "\n",
    "# calculate the experimental RBFEs\n",
    "# write these to a csv file\n",
    "with open(\"analysis/experimental_perturbations.csv\", \"w\") as exp_pert_file:\n",
    "    writer = csv.writer(exp_pert_file, delimiter=\",\")\n",
    "    writer.writerow([\"lig_1\",\"lig_2\",\"freenrg\",\"error\",\"engine\"])\n",
    "\n",
    "    for pert in perturbations:\n",
    "        lig_0 = pert.split(\"~\")[0]\n",
    "        lig_1 = pert.split(\"~\")[1]\n",
    "        exper_ddG = exper_val_dict[lig_1][0] - exper_val_dict[lig_0][0]\n",
    "        exper_err = math.sqrt(math.pow(exper_val_dict[lig_0][1], 2) + math.pow(exper_val_dict[lig_1][1], 2))\n",
    "        exper_diff_dict.update({pert:(exper_ddG, exper_err)})\n",
    "\n",
    "        writer.writerow([lig_0, lig_1, exper_ddG, exper_err, \"experimental\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Plotting\n",
    "<a id=\"plot\"></a>\n",
    "\n",
    "Now we have our computational and experimental in dicitonary format, we can turn this into a pandas dataframe. For plotting it is typically easier to work with the pandas library, which is why this next piece of code will reshape it to this.   \n",
    "\n",
    "Note that if pandas returns value errors at this step, it is likely there are ligands missing from either your FEP outputs or your experimental input. If a single repeat of a perturbation is missing, the code should be able to deal with this, but if a whole perturbation from the network file is missing there should be an error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freenrg_pert_dict = {}\n",
    "\n",
    "# construct dict with experimental freenrg and error and computed\n",
    "for pert in perturbations:\n",
    "    exp_ddG = exper_diff_dict[pert][0]\n",
    "    exp_err = exper_diff_dict[pert][1]\n",
    "    comp_ddG = comp_diff_dict[pert][0]\n",
    "    comp_err = comp_diff_dict[pert][1]\n",
    "    freenrg_pert_dict[pert] = [exp_ddG, exp_err, comp_ddG, comp_err]\n",
    "\n",
    "# want to put these in a joint dictionary so can convert into pandas df\n",
    "freenrg_df_pert = pd.DataFrame(freenrg_pert_dict, index=[\"freenrg_exp\", \"err_exp\", \"freenrg_fep\", \"err_fep\"]).transpose()\n",
    "\n",
    "# save our results to a file that can be opened in e.g. Excel.\n",
    "freenrg_df_pert.to_csv(\"analysis/fep_diff_results_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot our results against the experimental data. This is best done using a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatter plot\n",
    "plt.rc('font', size=12)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# get these based on which column the data is in.\n",
    "x = freenrg_df_pert[\"freenrg_exp\"]\n",
    "y = freenrg_df_pert[\"freenrg_fep\"]\n",
    "y_er = freenrg_df_pert[\"err_exp\"]\n",
    "x_er = freenrg_df_pert[\"err_exp\"]\n",
    "\n",
    "# plotting the scatterplot\n",
    "scatterplot = [plt.scatter(x, y, zorder=10)]\n",
    "\n",
    "#plotting error bars\n",
    "plt.errorbar(x , y,\n",
    "            yerr=y_er,\n",
    "            # xerr=x_er,   # comment this line to hide experimental error bars \\\n",
    "                        # as this can sometimes overcrowd the plot.\n",
    "            ls=\"none\",\n",
    "            lw=0.5, \n",
    "            capsize=2,\n",
    "            color=\"black\",\n",
    "            zorder=5\n",
    "            )\n",
    "\n",
    "# plot 1/2 kcal bounds:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-100.25,99.75],\n",
    "                y1=[-99.75, 100.25],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                alpha=0.3,\n",
    "                color=\"grey\")\n",
    "# upper bound:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-99.5,100.5],\n",
    "                y1=[-99.75, 100.25],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                color=\"grey\", \n",
    "                alpha=0.2)\n",
    "# lower bound:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-100.25,99.75],\n",
    "                y1=[-100.5, 99.5],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                color=\"grey\", \n",
    "                alpha=0.2)\n",
    "\n",
    "# get the bounds. This can be done with min/max or simply by hand.\n",
    "all_freenrg_values = np.concatenate([freenrg_df_pert[\"freenrg_exp\"].values,freenrg_df_pert[\"freenrg_fep\"].values])\n",
    "min_lim = min(all_freenrg_values)   \n",
    "max_lim = max(all_freenrg_values)\n",
    "\n",
    "# for a scatterplot we want the axis ranges to be the same. \n",
    "plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "plt.axhline(color=\"black\", zorder=1)\n",
    "plt.axvline(color=\"black\", zorder=1)\n",
    "\n",
    "plt.ylabel(\"Computed $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xlabel(\"Experimental $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "plt.savefig(\"analysis/fep_vs_exp_scatterplot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysing per Ligand\n",
    "<a id=\"lig\"></a>\n",
    "\n",
    "### 2.1. Freenrgworkflows\n",
    "<a id=\"fwf\"></a>\n",
    "\n",
    "We can also use [FreeNrgWorkFlows](https://github.com/michellab/freenrgworkflows) to analyse our predictions. Instead of just computing ΔΔG values for each transformation, we would like to estimate the ΔΔG value for each individual ligand. There are some involved algorithms needed for these steps which is what FreeNrgWorkFlows takes care of for us. Earlier, we imported some slightly adjusted FreenrgWorkFlows functions from the copy of the folder in this workshop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will analyse our network using the `NetworkAnalyser()` and add all our data in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nA = networkanalysis.NetworkAnalyser()\n",
    "\n",
    "first_file = False\n",
    "for file_name in results_files:\n",
    "    if first_file is False:\n",
    "        nA.read_perturbations_pandas(file_name, comments='#')\n",
    "        first_file = True\n",
    "    else:\n",
    "        # add more replicates to the graph. FreeNrgWorkflows will take care of averaging \n",
    "        # the free energies as well as propagating the error.\n",
    "        nA.add_data_to_graph_pandas(file_name)\n",
    "\n",
    "computed_relative_DDGs = nA.freeEnergyInKcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_relative_DDGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we can load in the experimental data. We already calculated these earlier using Freenrgworkflows as `experimental_ddGs`, so now we can add these directly for our analysis.   \n",
    "\n",
    "If we have added any intermediate ligands (such as the setup, where we included the intermediate_H), we also want to define the regular expression here. Ligands containing this pattern will be excluded from calculations that compare to experimental values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freenrg_dict = {}\n",
    "\n",
    "intermediate_string=\"\"\n",
    "\n",
    "# construct dict with experimental freenrg and error.\n",
    "for ligand in exper_val_dict:\n",
    "    # only consider the values for the ligands in this network\n",
    "    if ligand in ligands:\n",
    "        freenrg = exper_val_dict[ligand][0]\n",
    "        error = exper_val_dict[ligand][1]\n",
    "        freenrg_dict[ligand] = [freenrg, error]\n",
    "\n",
    "# append computed freenrg and error.\n",
    "for item in computed_relative_DDGs:\n",
    "        ligand = list(item.keys())[0]\n",
    "        freenrg = list(item.values())[0]\n",
    "        error = list(item.values())[1]\n",
    "                \n",
    "        if intermediate_string is not ligand:\n",
    "            freenrg_dict[ligand].append(freenrg)\n",
    "            freenrg_dict[ligand].append(error)\n",
    "\n",
    "freenrg_df = pd.DataFrame(freenrg_dict, index=[\"freenrg_exp\", \"err_exp\", \"freenrg_fep\", \"err_fep\"]).transpose()\n",
    "\n",
    "# save our results to a file that can be opened in e.g. Excel.\n",
    "freenrg_df.to_csv(\"analysis/fep_results_table_per_ligand.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Plotting\n",
    "<a id=\"plot2\"></a>\n",
    "\n",
    "We can also plot a scatter plot for the ΔΔG per ligand below in a similar manner to how we plotted the perturbations before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.scatter(freenrg_df[\"freenrg_exp\"], freenrg_df[\"freenrg_fep\"], zorder=10)\n",
    "\n",
    "# plot 1/2 kcal bounds:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-100.25,99.75],\n",
    "\t\t\t\ty1=[-99.75, 100.25],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\talpha=0.3,\n",
    "\t\t\t\tcolor=\"grey\")\n",
    "# upper bound:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-99.5,100.5],\n",
    "\t\t\t\ty1=[-99.75, 100.25],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\tcolor=\"grey\", \n",
    "\t\t\t\talpha=0.2)\n",
    "# lower bound:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-100.25,99.75],\n",
    "\t\t\t\ty1=[-100.5, 99.5],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\tcolor=\"grey\", \n",
    "\t\t\t\talpha=0.2)\n",
    "\n",
    "# plot error bars:\n",
    "yerr = freenrg_df[\"err_fep\"]\n",
    "xerr = freenrg_df[\"err_exp\"]\n",
    "\n",
    "plt.errorbar(freenrg_df[\"freenrg_exp\"], freenrg_df[\"freenrg_fep\"], \n",
    "            yerr=yerr,\n",
    "            xerr=xerr,   # comment this line to hide experimental error bars \\\n",
    "                         # as this can sometimes overcrowd the plot.\n",
    "            ls=\"none\",\n",
    "            lw=0.5, \n",
    "            capsize=2,\n",
    "            color=\"black\",\n",
    "            zorder=5\n",
    "            )\n",
    "\n",
    "# format the plot further.\n",
    "plt.axhline(color=\"black\", zorder=1)\n",
    "plt.axvline(color=\"black\", zorder=1)\n",
    "plt.ylabel(\"Predicted $\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xlabel(\"Experimental $\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "# get the bounds. This can be done with min/max or simply by hand.\n",
    "all_freenrg_values = np.concatenate([freenrg_df[\"freenrg_exp\"].values,freenrg_df[\"freenrg_fep\"].values])\n",
    "min_lim = min(all_freenrg_values)\n",
    "max_lim = max(all_freenrg_values)\n",
    "\n",
    "# for a scatterplot we want the axis ranges to be the same. \n",
    "plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "plt.savefig(\"analysis/fep_vs_exp_scatterplot_per_ligand.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can also plot a bar graph for the ΔΔG per ligand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate an empty figure with fixed dimensions.\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# determine positions for X axis labels.\n",
    "x_locs = np.arange(len(freenrg_df))\n",
    "\n",
    "# set bar width\n",
    "width = 0.35  \n",
    "\n",
    "# plot both our experimental and FEP free energies using an offset on the x position so bars don't overlap.\n",
    "ax.bar(x_locs - width/2, height=freenrg_df[\"freenrg_exp\"], width=width, yerr=freenrg_df[\"err_exp\"],\n",
    "                label='Experimental')\n",
    "ax.bar(x_locs + width/2, height=freenrg_df[\"freenrg_fep\"], width=width, yerr=freenrg_df[\"err_fep\"],\n",
    "                label='FEP')\n",
    " \n",
    "# format the plot further.\n",
    "plt.axhline(color=\"black\")\n",
    "plt.ylabel(\"$\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xticks(x_locs, freenrg_df.index, rotation=70, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"analysis/fep_vs_exp_barplot_per_ligand.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Satistical analysis\n",
    "<a id=\"stats\"></a>\n",
    "\n",
    "We also want to carry out a statistical analysis of our results. Below are examples of how to re-sample from the data in order to obtain error bars on correlation coefficients, MUE and Kendall tau. Returned are confidence intervals of 65% and the median of the distribution. It is important to take these confidences into account as FEP predictions have a variance associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stats = stats.freeEnergyStats()\n",
    "_stats.generate_statistics(computed_relative_DDGs,experimental_DDGs,repeats=10000)\n",
    "r_confidence = _stats.R_confidence\n",
    "tau_confidence = _stats.tau_confidence\n",
    "mue_confidence = _stats.mue_confidence\n",
    "print (\"R confidence is:   %.2f < %.2f < %.2f\" %(r_confidence[1], r_confidence[0], r_confidence[2]))\n",
    "print (\"MUE confidence is: %.2f < %.2f < %.2f\" %(mue_confidence[1], mue_confidence[0], mue_confidence[2]))\n",
    "print (\"Tau confidence is: %.2f < %.2f < %.2f\" %(tau_confidence[1], tau_confidence[0], tau_confidence[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Outliers\n",
    "<a id=\"outliers\"></a>\n",
    "As the network analysis performs a weighted least squares regression, a badly computed perturbation can impact the overall quality of our network. Below, we want to annotate any outliers for our perturbations (on the scatter plot) so we can exclude them, rerun  our network analysis, and improve this. We can do this in one of two ways - either we can remove the values that disagree more substantially with the experimental, as below, or, if no experimental values are available, we can consider the error of the perturbation.\n",
    "\n",
    "First, let's look at our scatter plot with the outlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_outliers_to_annotate = 1\n",
    "\n",
    "# get an array of the MUE values comparing experimental and FEP values. Take the absolute values.\n",
    "mue_values = abs(freenrg_df_pert[\"freenrg_exp\"] - freenrg_df_pert[\"freenrg_fep\"])\n",
    "\n",
    "# find the n ligand names that are outliers.\n",
    "outlier_names = mue_values.nlargest(number_outliers_to_annotate).index.values.tolist()\n",
    "print(outlier_names)\n",
    "\n",
    "# construct a list of labels to annotate the scatterplot with.\n",
    "annot_labels = []\n",
    "colours = []\n",
    "for ligand in freenrg_df_pert.index.values:\n",
    "    # if the ligand is an outlier, append the name to the annotation labels list.\n",
    "    if ligand in outlier_names:\n",
    "        annot_labels.append(ligand)\n",
    "        colours.append(\"red\")\n",
    "    else:\n",
    "        # if the ligand is not an outlier, append an empty string to the annotation labels list.\n",
    "        annot_labels.append(\"\")\n",
    "        colours.append(\"blue\")\n",
    "\n",
    "# Create the same scatterplot as above. Can include some more of the formatting if needed.\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.scatter(freenrg_df_pert[\"freenrg_exp\"], freenrg_df_pert[\"freenrg_fep\"], zorder=10, c=colours)\n",
    "plt.plot((-10,10),(-10,10))\n",
    "plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "# then, after generating the figure, we can annotate:\n",
    "for i, txt in enumerate(annot_labels):\n",
    "    plt.annotate(txt, \n",
    "                 (freenrg_df_pert[\"freenrg_exp\"].values.tolist()[i]+0.1,     # x coords\n",
    "                  freenrg_df_pert[\"freenrg_fep\"].values.tolist()[i]+0.1),    # y coords\n",
    "                 size=20, color=\"crimson\")\n",
    "\n",
    "plt.savefig(\"analysis/fep_vs_exp_outlier_plot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our largest outlier is 'jmc_30~ejm_50'. Looking at the error below, we can also see that this perturbation has the largest SEM for between the replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer \n",
    "error_table = pd.DataFrame(freenrg_df_pert[\"err_fep\"]).sort_values(by=\"err_fep\")\n",
    "\n",
    "# we can write the table to a csv file that can be opened in e.g. Excel.\n",
    "error_table.to_csv(\"analysis/error_table.csv\")\n",
    "error_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Exercise 2.4.1: Excluding intermediates from the Network analysis</b>\n",
    "</div>\n",
    "\n",
    "Try exculding this perturbation and rerunning the above Network analysis. First, we need to remove the perturbation. Then, we need to make sure that our new output image is being saved using a different file path. Adjust these in the cells below where the #FIXME is.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the perturbation\n",
    "# FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "\n",
    "```python\n",
    "perturbations.remove(\"jmc_30~ejm_50\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are just copies of the cells we want to rerun:\n",
    "\n",
    "# rewrite the results files for this network\n",
    "results_all_files = []\n",
    "no_repeats=6\n",
    "# create a list of the results files\n",
    "for r in list(range(1, no_repeats+1)):\n",
    "    file_name = f\"analysis/repeat_{r}_tyk2.csv\"\n",
    "    results_all_files.append(file_name)\n",
    "\n",
    "results_files = []\n",
    "\n",
    "for file in results_all_files:\n",
    "    new_file_name = f\"analysis/results_{results_all_files.index(file)}.csv\"  #FIXME\n",
    "    with open(new_file_name, \"w\") as result_file:\n",
    "\n",
    "        writer = csv.writer(result_file, delimiter=\",\")\n",
    "        writer.writerow([\"lig_1\",\"lig_2\",\"freenrg\",\"error\",\"engine\"])\n",
    "\n",
    "        for row, index in pd.read_csv(file).iterrows():\n",
    "            pert = f\"{index['lig_1']}~{index['lig_2']}\"\n",
    "            if pert in perturbations:\n",
    "                writer.writerow([index['lig_1'], index['lig_2'], index['freenrg'], index['error'], index['engine']])    \n",
    "\n",
    "        results_files.append(new_file_name)\n",
    "\n",
    "# analyse the network again\n",
    "nA = networkanalysis.NetworkAnalyser()\n",
    "\n",
    "first_file = False\n",
    "for file_name in results_files:\n",
    "    if first_file is False:\n",
    "        nA.read_perturbations_pandas(file_name, comments='#')\n",
    "        first_file = True\n",
    "    else:\n",
    "        # add more replicates to the graph. FreeNrgWorkflows will take care of averaging \n",
    "        # the free energies as well as propagating the error.\n",
    "        nA.add_data_to_graph_pandas(file_name)\n",
    "\n",
    "computed_relative_DDGs = nA.freeEnergyInKcal\n",
    "\n",
    "# make the dictionary for plotting again\n",
    "\n",
    "freenrg_dict = {}\n",
    "\n",
    "intermediate_string=\" \"\n",
    "\n",
    "# construct dict with experimental freenrg and error.\n",
    "for ligand in exper_val_dict:\n",
    "    # only consider the values for the ligands in this network\n",
    "    if ligand in ligands:\n",
    "        freenrg = exper_val_dict[ligand][0]\n",
    "        error = exper_val_dict[ligand][1]\n",
    "        freenrg_dict[ligand] = [freenrg, error]\n",
    "\n",
    "# append computed freenrg and error.\n",
    "for item in computed_relative_DDGs:\n",
    "        ligand = list(item.keys())[0]\n",
    "        freenrg = list(item.values())[0]\n",
    "        error = list(item.values())[1]\n",
    "                \n",
    "        if intermediate_string not in ligand:\n",
    "            freenrg_dict[ligand].append(freenrg)\n",
    "            freenrg_dict[ligand].append(error)\n",
    "\n",
    "freenrg_df = pd.DataFrame(freenrg_dict, index=[\"freenrg_exp\", \"err_exp\", \"freenrg_fep\", \"err_fep\"]).transpose()\n",
    "\n",
    "# save our results to a file that can be opened in e.g. Excel.\n",
    "freenrg_df.to_csv(\"analysis/fep_results_table_per_ligand.csv\" #FIXME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "\n",
    "```python\n",
    "# answer\n",
    "# below are just copies of the cells we want to rerun:\n",
    "\n",
    "# rewrite the results files for this network\n",
    "results_all_files = []\n",
    "no_repeats=6\n",
    "# create a list of the results files\n",
    "for r in list(range(1, no_repeats+1)):\n",
    "    file_name = f\"analysis/repeat_{r}_tyk2.csv\"\n",
    "    results_all_files.append(file_name)\n",
    "\n",
    "results_files = []\n",
    "\n",
    "for file in results_all_files:\n",
    "    new_file_name = f\"analysis/results_{results_all_files.index(file)}_excluded_perturbation.csv\"\n",
    "    with open(new_file_name, \"w\") as result_file:\n",
    "\n",
    "        writer = csv.writer(result_file, delimiter=\",\")\n",
    "        writer.writerow([\"lig_1\",\"lig_2\",\"freenrg\",\"error\",\"engine\"])\n",
    "\n",
    "        for row, index in pd.read_csv(file).iterrows():\n",
    "            pert = f\"{index['lig_1']}~{index['lig_2']}\"\n",
    "            if pert in perturbations:\n",
    "                writer.writerow([index['lig_1'], index['lig_2'], index['freenrg'], index['error'], index['engine']])    \n",
    "\n",
    "        results_files.append(new_file_name)\n",
    "\n",
    "# analyse the network again\n",
    "nA = networkanalysis.NetworkAnalyser()\n",
    "\n",
    "first_file = False\n",
    "for file_name in results_files:\n",
    "    if first_file is False:\n",
    "        nA.read_perturbations_pandas(file_name, comments='#')\n",
    "        first_file = True\n",
    "    else:\n",
    "        # add more replicates to the graph. FreeNrgWorkflows will take care of averaging \n",
    "        # the free energies as well as propagating the error.\n",
    "        nA.add_data_to_graph_pandas(file_name)\n",
    "\n",
    "computed_relative_DDGs = nA.freeEnergyInKcal\n",
    "\n",
    "# make the dictionary for plotting again\n",
    "\n",
    "freenrg_dict = {}\n",
    "\n",
    "intermediate_string=\" \"\n",
    "\n",
    "# construct dict with experimental freenrg and error.\n",
    "for ligand in exper_val_dict:\n",
    "    # only consider the values for the ligands in this network\n",
    "    if ligand in ligands:\n",
    "        freenrg = exper_val_dict[ligand][0]\n",
    "        error = exper_val_dict[ligand][1]\n",
    "        freenrg_dict[ligand] = [freenrg, error]\n",
    "\n",
    "# append computed freenrg and error.\n",
    "for item in computed_relative_DDGs:\n",
    "        ligand = list(item.keys())[0]\n",
    "        freenrg = list(item.values())[0]\n",
    "        error = list(item.values())[1]\n",
    "                \n",
    "        if intermediate_string not in ligand:\n",
    "            freenrg_dict[ligand].append(freenrg)\n",
    "            freenrg_dict[ligand].append(error)\n",
    "\n",
    "freenrg_df = pd.DataFrame(freenrg_dict, index=[\"freenrg_exp\", \"err_exp\", \"freenrg_fep\", \"err_fep\"]).transpose()\n",
    "\n",
    "# save our results to a file that can be opened in e.g. Excel.\n",
    "freenrg_df.to_csv(\"analysis/fep_results_table_per_ligand_excluded_perturbation.csv\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.scatter(freenrg_df[\"freenrg_exp\"], freenrg_df[\"freenrg_fep\"], zorder=10)\n",
    "\n",
    "# plot 1/2 kcal bounds:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-100.25,99.75],\n",
    "\t\t\t\ty1=[-99.75, 100.25],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\talpha=0.3,\n",
    "\t\t\t\tcolor=\"grey\")\n",
    "# upper bound:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-99.5,100.5],\n",
    "\t\t\t\ty1=[-99.75, 100.25],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\tcolor=\"grey\", \n",
    "\t\t\t\talpha=0.2)\n",
    "# lower bound:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-100.25,99.75],\n",
    "\t\t\t\ty1=[-100.5, 99.5],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\tcolor=\"grey\", \n",
    "\t\t\t\talpha=0.2)\n",
    "\n",
    "# plot error bars:\n",
    "yerr = freenrg_df[\"err_fep\"]\n",
    "xerr = freenrg_df[\"err_exp\"]\n",
    "\n",
    "plt.errorbar(freenrg_df[\"freenrg_exp\"], freenrg_df[\"freenrg_fep\"], \n",
    "            yerr=yerr,\n",
    "            xerr=xerr,   # comment this line to hide experimental error bars \\\n",
    "                         # as this can sometimes overcrowd the plot.\n",
    "            ls=\"none\",\n",
    "            lw=0.5, \n",
    "            capsize=2,\n",
    "            color=\"black\",\n",
    "            zorder=5\n",
    "            )\n",
    "\n",
    "# format the plot further.\n",
    "plt.axhline(color=\"black\", zorder=1)\n",
    "plt.axvline(color=\"black\", zorder=1)\n",
    "plt.ylabel(\"Predicted $\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xlabel(\"Experimental $\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "# get the bounds. This can be done with min/max or simply by hand.\n",
    "all_freenrg_values = np.concatenate([freenrg_df[\"freenrg_exp\"].values,freenrg_df[\"freenrg_fep\"].values])\n",
    "min_lim = min(all_freenrg_values)\n",
    "max_lim = max(all_freenrg_values)\n",
    "\n",
    "# for a scatterplot we want the axis ranges to be the same. \n",
    "plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "plt.savefig(\"analysis/fep_vs_exp_scatterplot_per_ligand.png\"  #FIXME, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.scatter(freenrg_df[\"freenrg_exp\"], freenrg_df[\"freenrg_fep\"], zorder=10)\n",
    "\n",
    "# plot 1/2 kcal bounds:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-100.25,99.75],\n",
    "\t\t\t\ty1=[-99.75, 100.25],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\talpha=0.3,\n",
    "\t\t\t\tcolor=\"grey\")\n",
    "# upper bound:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-99.5,100.5],\n",
    "\t\t\t\ty1=[-99.75, 100.25],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\tcolor=\"grey\", \n",
    "\t\t\t\talpha=0.2)\n",
    "# lower bound:\n",
    "plt.fill_between(\n",
    "\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\ty2=[-100.25,99.75],\n",
    "\t\t\t\ty1=[-100.5, 99.5],\n",
    "\t\t\t\tlw=0, \n",
    "\t\t\t\tzorder=-10,\n",
    "\t\t\t\tcolor=\"grey\", \n",
    "\t\t\t\talpha=0.2)\n",
    "\n",
    "# plot error bars:\n",
    "yerr = freenrg_df[\"err_fep\"]\n",
    "xerr = freenrg_df[\"err_exp\"]\n",
    "\n",
    "plt.errorbar(freenrg_df[\"freenrg_exp\"], freenrg_df[\"freenrg_fep\"], \n",
    "            yerr=yerr,\n",
    "            xerr=xerr,   # comment this line to hide experimental error bars \\\n",
    "                         # as this can sometimes overcrowd the plot.\n",
    "            ls=\"none\",\n",
    "            lw=0.5, \n",
    "            capsize=2,\n",
    "            color=\"black\",\n",
    "            zorder=5\n",
    "            )\n",
    "\n",
    "# format the plot further.\n",
    "plt.axhline(color=\"black\", zorder=1)\n",
    "plt.axvline(color=\"black\", zorder=1)\n",
    "plt.ylabel(\"Predicted $\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xlabel(\"Experimental $\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "# get the bounds. This can be done with min/max or simply by hand.\n",
    "all_freenrg_values = np.concatenate([freenrg_df[\"freenrg_exp\"].values,freenrg_df[\"freenrg_fep\"].values])\n",
    "min_lim = min(all_freenrg_values)\n",
    "max_lim = max(all_freenrg_values)\n",
    "\n",
    "# for a scatterplot we want the axis ranges to be the same. \n",
    "plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "plt.savefig(\"analysis/fep_vs_exp_scatterplot_per_ligand_excluded_perturbation.png\", dpi=300)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate an empty figure with fixed dimensions.\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# determine positions for X axis labels.\n",
    "x_locs = np.arange(len(freenrg_df))\n",
    "\n",
    "# set bar width\n",
    "width = 0.35  \n",
    "\n",
    "# plot both our experimental and FEP free energies using an offset on the x position so bars don't overlap.\n",
    "ax.bar(x_locs - width/2, height=freenrg_df[\"freenrg_exp\"], width=width, yerr=freenrg_df[\"err_exp\"],\n",
    "                label='Experimental')\n",
    "ax.bar(x_locs + width/2, height=freenrg_df[\"freenrg_fep\"], width=width, yerr=freenrg_df[\"err_fep\"],\n",
    "                label='FEP')\n",
    " \n",
    "# format the plot further.\n",
    "plt.axhline(color=\"black\")\n",
    "plt.ylabel(\"$\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xticks(x_locs, freenrg_df.index, rotation=70, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"analysis/fep_vs_exp_barplot_per_ligand.png\"  #FIXME, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "\n",
    "```python\n",
    "# initiate an empty figure with fixed dimensions.\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# determine positions for X axis labels.\n",
    "x_locs = np.arange(len(freenrg_df))\n",
    "\n",
    "# set bar width\n",
    "width = 0.35  \n",
    "\n",
    "# plot both our experimental and FEP free energies using an offset on the x position so bars don't overlap.\n",
    "ax.bar(x_locs - width/2, height=freenrg_df[\"freenrg_exp\"], width=width, yerr=freenrg_df[\"err_exp\"],\n",
    "                label='Experimental')\n",
    "ax.bar(x_locs + width/2, height=freenrg_df[\"freenrg_fep\"], width=width, yerr=freenrg_df[\"err_fep\"],\n",
    "                label='FEP')\n",
    " \n",
    "# format the plot further.\n",
    "plt.axhline(color=\"black\")\n",
    "plt.ylabel(\"$\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xticks(x_locs, freenrg_df.index, rotation=70, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"analysis/fep_vs_exp_barplot_per_ligand_excluded_perturbation.png\", dpi=300)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do these graphs look different from the previous ones? Below we will also rerun our statistical tests. Is our statistical analysis improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stats = stats.freeEnergyStats()\n",
    "_stats.generate_statistics(computed_relative_DDGs,experimental_DDGs,repeats=10000)\n",
    "r_confidence = _stats.R_confidence\n",
    "tau_confidence = _stats.tau_confidence\n",
    "mue_confidence = _stats.mue_confidence\n",
    "print (\"R confidence is:   %.2f < %.2f < %.2f\" %(r_confidence[1], r_confidence[0], r_confidence[2]))\n",
    "print (\"MUE confidence is: %.2f < %.2f < %.2f\" %(mue_confidence[1], mue_confidence[0], mue_confidence[2]))\n",
    "print (\"Tau confidence is: %.2f < %.2f < %.2f\" %(tau_confidence[1], tau_confidence[0], tau_confidence[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "        \n",
    "Yes, our graphs look different.         \n",
    "\n",
    "Excluding the perturbation should have improved the statistical tests.      \n",
    "previous output was:        \n",
    "R confidence is:   -0.25 < -0.22 < -0.18        \n",
    "MUE confidence is: 1.60 < 1.63 < 1.67       \n",
    "Tau confidence is: -0.22 < -0.20 < -0.16        \n",
    "        \n",
    "the results with the excluded perturbation are:     \n",
    "R confidence is:   0.49 < 0.52 < 0.56       \n",
    "MUE confidence is: 0.88 < 0.92 < 0.95       \n",
    "Tau confidence is: 0.30 < 0.33 < 0.37       \n",
    "\n",
    "Also visually, both the scatter and the bar plot show better agreement with experimental data.      \n",
    "This is particularly true for example for 'jmc30', where the previous output for the FEP result per ligand was almost the complete opposite of the experimental, whereas now it has no significant difference to the experimental.      \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Exercise 2.4.2: Visualising the ligand</b>\n",
    "</div>\n",
    "\n",
    "Based on our results, we may also want to visualise which of our ligands had the highest binding affinity.\n",
    "\n",
    "**Hint:** First, sort the data frame to find the ligand with the best binding affinity and then use BSS to visualise it like in the introductionary workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "\n",
    "```python\n",
    "results_table = pd.DataFrame(freenrg_df[\"freenrg_fep\"]).sort_values(by=\"freenrg_fep\")\n",
    "\n",
    "results_table.to_csv(\"analysis/fep_predictions_excluded_perturbation.csv\")\n",
    "results_table\n",
    "\n",
    "BSS.Notebook.View(\"inputs/ligands/ejm44.sdf\").system()\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has covered the basics of some analysis that can be done on our RBFE results. There are many ways to customise this, and it is also a good idea to check out the further reading for a good overview of FEP data reporting best practices: [Section 8.7, LiveComs Best Practices for Alchemical Free Energy Calculations](https://livecomsjournal.org/index.php/livecoms/article/view/v2i1e18378).\n",
    "\n",
    "As for the setup workshop, all the generated graphs and tables outputs are available in the 'example_output' folder.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('biosimspace-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d79bb85316fa6c998e385cc39903e056bffeb3f6098416e9c269ddd32175e919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
